In this project, I have successfully employed SLAM and navigation functions using the NAV2 stack to enable the autonomous navigation of the robot. The project was divided into simulation and real-life implementation. For the simulation, the robot was fully implemented and simulated in Gazebo. As for the real-life implementation, I used a spare Kinect v1 as input for the robot and employed a script that converts its input to laserscan data for the SLAM algorithm to use for mapping. Additionally, I utilized a custom ros2_control hardware interface, which leverages an Arduino sketch using the ros_arduino_bridge package, to control the robot using an L296N module. The only thing currently missing from the build is the motors required to drive the robot, which are on their way.
